{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Return the word term frequency normalized by the maximum frequency of a term in the document and the max frequency fetched in the document\n",
    "def calculateTermFrequencies(document, prefix = \"./\"):\n",
    "    words = {}\n",
    "    f = open(prefix + document)\n",
    "    for l in f.readlines():\n",
    "        words = calculateLineTermFrequencies(l, words)\n",
    "    f.close()\n",
    "    max_frequency = sorted(words.items(), key=lambda kv: kv[1], reverse = True)\n",
    "    mf = max_frequency[0][1]\n",
    "    for w in words:\n",
    "        words[w] /= mf\n",
    "    return words, mf\n",
    "\n",
    "# Return the frequency of the words in a string and adds it to the words dictinary\n",
    "def calculateLineTermFrequencies(line, words):\n",
    "    for token in nltk.word_tokenize(line):\n",
    "        words[token] = words[token] + 1 if token in words else 1\n",
    "    return words\n",
    "\n",
    "# Calculates the inverse document frequency of the terms in a list of documents\n",
    "def calculateIDFCorpus(corpora, prefix = \"./\"):\n",
    "    documents = len(corpora)\n",
    "    IDF_w = {}\n",
    "    total_term_frequencies = {}\n",
    "    total_words = 0\n",
    "    for d in corpora:\n",
    "        words, mf = calculateTermFrequencies(d, prefix)\n",
    "        for w in words:\n",
    "            IDF_w[w] = IDF_w[w] + 1 if w in IDF_w else 1\n",
    "            total_term_frequencies[w] = total_term_frequencies[w] + (words[w] * mf) if w in total_term_frequencies else words[w] * mf\n",
    "            total_words += words[w] * mf\n",
    "    IDF = {}\n",
    "    for w in IDF_w:\n",
    "        IDF[w] = math.log(documents/(1 + IDF_w[w]))\n",
    "    return IDF, IDF_w, total_term_frequencies, total_words\n",
    "        \n",
    "\n",
    "# Calculates the inverse document frequency of a term in the documents found in a system folder\n",
    "def calculateIDFDirectory(directory, prefix = \"./\"):\n",
    "    mypath = prefix + directory if prefix else directory\n",
    "    files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    return calculateIDFCorpus(files, mypath + \"/\")\n",
    "\n",
    "# Calculates the TF-IDF of a document using a generated IDF or an specific directory\n",
    "def TFIDF(document, directory=\"./\", IDF = None, prefix=\"./\"):\n",
    "    df = prefix + directory + \"/\" if directory else prefix\n",
    "    tf, mf = calculateTermFrequencies(document, prefix = df)\n",
    "    TFIDF = {}\n",
    "    if not IDF:\n",
    "        IDF, IDF_w, total_term_frequencies, total_words = calculateIDFDirectory(directory, prefix)\n",
    "    for w in tf:\n",
    "        TFIDF[w] = tf[w] * IDF[w]\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"Los caminos de la vida no son como yo pensaba, no son como imaginaba, no son como yo creía\"\n",
    "prefix = \"/home/mcampos/SoldAI/Repos/sar-machine-learning-toolkit/soldaimltk/classification/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Los': 1, 'caminos': 1, 'de': 1, 'la': 1, 'vida': 1, 'no': 3, 'son': 3, 'como': 3, 'yo': 2, 'pensaba': 1, ',': 2, 'imaginaba': 1, 'creía': 1}\n"
     ]
    }
   ],
   "source": [
    "freqs = calculateLineTermFrequencies(line, {})\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'Los': 0.3333333333333333, 'caminos': 0.3333333333333333, 'de': 0.3333333333333333, 'la': 0.3333333333333333, 'vida': 0.3333333333333333, 'no': 1.0, 'son': 1.0, 'como': 1.0, 'yo': 0.6666666666666666, 'pensaba': 0.3333333333333333, ',': 0.6666666666666666, 'imaginaba': 0.3333333333333333, 'creía': 0.3333333333333333}, 3)\n"
     ]
    }
   ],
   "source": [
    "print(calculateTermFrequencies('test.txt', prefix = prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********IDF**********\n",
      "{'Eres': 0.6931471805599453, 'el': 0.6931471805599453, 'caminos': -0.2231435513142097, 'largo': 0.6931471805599453, 'que': 0.6931471805599453, 'un': 0.6931471805599453, 'día': 0.6931471805599453, 'debo': 0.6931471805599453, 'caminar': 0.6931471805599453, ',': -0.2231435513142097, 'como': -0.2231435513142097, 'una': 0.6931471805599453, 'biografía': 0.6931471805599453, 'y': 0.6931471805599453, 'con': 0.6931471805599453, 'cenizas': 0.6931471805599453, 'del': 0.6931471805599453, 'ayer': 0.6931471805599453, 'Los': 0.0, 'de': 0.0, 'la': 0.0, 'vida': 0.0, 'no': 0.0, 'son': 0.0, 'yo': 0.0, 'pensaba': 0.0, 'imaginaba': 0.0, 'creía': 0.0}\n",
      "**********IDF_w**********\n",
      "{'Eres': 1, 'el': 1, 'caminos': 4, 'largo': 1, 'que': 1, 'un': 1, 'día': 1, 'debo': 1, 'caminar': 1, ',': 4, 'como': 4, 'una': 1, 'biografía': 1, 'y': 1, 'con': 1, 'cenizas': 1, 'del': 1, 'ayer': 1, 'Los': 3, 'de': 3, 'la': 3, 'vida': 3, 'no': 3, 'son': 3, 'yo': 3, 'pensaba': 3, 'imaginaba': 3, 'creía': 3}\n",
      "**********total_term_frequencies**********\n",
      "{'Eres': 1.0, 'el': 1.0, 'caminos': 4.0, 'largo': 2.0, 'que': 1.0, 'un': 1.0, 'día': 1.0, 'debo': 1.0, 'caminar': 1.0, ',': 8.0, 'como': 10.0, 'una': 1.0, 'biografía': 1.0, 'y': 1.0, 'con': 1.0, 'cenizas': 1.0, 'del': 1.0, 'ayer': 1.0, 'Los': 3.0, 'de': 3.0, 'la': 3.0, 'vida': 3.0, 'no': 9.0, 'son': 9.0, 'yo': 6.0, 'pensaba': 3.0, 'imaginaba': 3.0, 'creía': 3.0}\n",
      "**********total_words**********\n",
      "83.0\n"
     ]
    }
   ],
   "source": [
    "IDF, IDF_w, total_term_frequencies, total_words = calculateIDFDirectory(\"data\", \"/home/mcampos/SoldAI/Repos/sar-machine-learning-toolkit/soldaimltk/classification/\")\n",
    "print(\"*\" *10 + \"IDF\" + \"*\" * 10)\n",
    "print(IDF)\n",
    "print(\"*\" *10 + \"IDF_w\" + \"*\" * 10)\n",
    "print(IDF_w)\n",
    "print(\"*\" *10 + \"total_term_frequencies\" + \"*\"*10)\n",
    "print(total_term_frequencies)\n",
    "print(\"*\" *10 + \"total_words\" + \"*\"*10)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Eres': 0.34657359027997264, 'el': 0.34657359027997264, 'caminos': -0.11157177565710485, 'largo': 0.6931471805599453, 'que': 0.34657359027997264, 'un': 0.34657359027997264, 'día': 0.34657359027997264, 'debo': 0.34657359027997264, 'caminar': 0.34657359027997264, ',': -0.2231435513142097, 'como': -0.11157177565710485, 'una': 0.34657359027997264, 'biografía': 0.34657359027997264, 'y': 0.34657359027997264, 'con': 0.34657359027997264, 'cenizas': 0.34657359027997264, 'del': 0.34657359027997264, 'ayer': 0.34657359027997264}\n"
     ]
    }
   ],
   "source": [
    "tfidf = TFIDF(\"test3.txt\", directory=\"data\", prefix = \"/home/mcampos/SoldAI/Repos/sar-machine-learning-toolkit/soldaimltk/classification/\")\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
